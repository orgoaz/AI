\documentclass{article}      
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\begin{document}

\title{%
  236501: Assignment \#1 \\
  \large Graph Search \\
    Fall Semester '17-'18}

\author{
  Avidan, Eyal \\
  \texttt{205796469}
  \and
  Goaz, Or \\
  \texttt{307950113}
}

\maketitle

\section*{Magic Bus}
\subsection*{1. Number of Permutations}
\begin{table}[!h!p]
\begin{center}
\begin{tabular}{l l}
\hline
\textbf{Number of orders} & \textbf{Number of route permutations} \\ \hline \hline
1 & 1 \\ \hline
2 & 6 \\ \hline
3 & 90 \\ \hline
4 & 2520 \\ \hline
5 & 113400 \\ \hline
6 & 7484400 \\ \hline
7 & 681080400 \\ \hline
8 & 81729648000 \\ \hline
9 & 12504636144000 \\ \hline
10 & 2375880867360000 \\ 
\hline\hline
\end{tabular}
\end{center}
\end{table}

 
\subsection*{2. Branching factor limits}
Since each operation drops off at least one passenger and/or picks up at least one, the branching factor $b$ can be thought of as the number of (distinct) locations where a passenger is awaiting pickup, or that location is a destination for a passenger onboard the bus.
Thus, the limits of the branching factors are
\begin{itemize}
\item The maximum branching factor is $k$, and occurs for example at the initial state (when all passengers are in distinct source locations). It isn't possible to have a higher value, since there are only $k$ passengers
\item The minimal branching factor is $1$, when we only have the last passenger to drop off (again, assuming they're the only passenger to reach that destination). There couldn't be a lower value, since a Goal State is defined that way. (Or a dead end, but we'll get to that)
\end{itemize}

Thus, $1 \leq b \leq k$

\subsection*{3. Is the graph circular}
The graph can't have any circles, since once we pick up a passenger, we can't pick them up ever again (and the same for dropping off). This can also be thought of mathemtically - we have $2k$ locations to pass through - thats a finite route length.

\textbf{Note:} we can have circles in our orders - two passengers with reversed destinations and sources. However, this question refers to the State Space, which comprises also of the current state of each passenger.

\subsection*{4. Definition of Goal States}
Goal states are defined by all passengers having arrived to their destination, the last of them arriving at the location of the goal state.
Formally,
$$
G = \left\{ (v, W, B, F) | W=B=\emptyset, F=[k], v\in T  \right\}
$$

\subsection*{5. Number of Goal States}
Assuming all order locations are distinct, we will have exactly $k$ goal states - the last drop off of each passenger.
This follows from the previous section, since all that matters is $v \in T$

\subsection*{6. Dead-Ends in graph}
As discussed in section 3, the route length is constrained, and on each step we decrement the number of locations left to visit.  Thus, we will always reach a state where there are $0$ passengers on the bus, and all passengers are at their destionation.

\subsection*{7. The \textbf{Successor} function}
\begin{equation}
Succ\left((v_1, W_1, B_1, F_1)\right) =  \left\{ 
	(v_2, W_2, B_2, F_2) \\  \vline \\ 
  \begin{aligned}
  & W_2 = W_1 \setminus \{i | s_i = v_2\} \\ 
  & B_2 = B_1 \cup (W_2 \setminus W_1) \setminus  \{i | t_i = v_2\} \\ 
  & F_2 = F_1 \cup (B_2 \setminus B_1) \\
  & v_2 \in \{s_i | i \in W_1 \} \cup \{t_i | i\in B_1\}
  \end{aligned}
\right\}
\end{equation}

\subsection*{8. Goal state depth limits}
Since we have to pass through $2k$ different locations to pick up and drop off each passenger, and with each succession we only (half-way) take care of one passenger, all goal states will be at depth $2k$.

\subsection*{9. Initial Experiment}
One of the orders is from junction \#23695 at (32.1022894, 34.9882995) to \#33320 at (32.0926573, 35.1022635) \\ 
A lower bound on the distance we need to drive for this order is: 10.78km \\ 
Path length: 161.11km \\ 
\\ 
Path.getDistance uses a list comprehension to extract the distance of each link in the path, and sums them

\subsection*{10. Problem Verification Experiment}
Junction idx: \#851288 \\ 
waiting for bus: [(23695, 33320)] \\ 
orders on bus: [(32056, 834603), (851288, 533396)] \\ 
finished orders: [(47521, 606430), (466524, 29249)] \\
Is goal? False

\subsection*{A*}
\subsubsection*{11. A* Experiment}
dsadsa

\subsubsection*{12. Conclusions on the sum of routes}
dsakldnaslk \\ 

not minimal – if all in same place…  \\
probably not maximal – if all different, it doesn’t count $t+i->s_i+1$ \\

dsakldsal \\

\subsection*{Greedy Algorithm}
\subsubsection*{13. Greedy Algorithm Experiment}
dsadsa
\begin{table}[]
\begin{center}
\begin{tabular}{l l}
\hline
\textbf{Input FIle} & \textbf{Solution cost (total distance in KM)} \\ \hline
TLV\_5 & dsadsa \\ \hline
SDEROT\_50 & dsadsa \\ \hline
HAIFA\_100 & dsadsa \\ \hline
BEER\_SHEVA\_100 & dsadsa \\ 
\hline\hline
\end{tabular}
\end{center}
\end{table}

\subsubsection*{14. Number of expanded junctions limits}
Without any knowledge on the scoring function, we would have to limit the number of junctions using the trivial constraints
\begin{itemize}
\item The maximal number is still $2k$
\item Since we don't have the distinct location constraint anymore, in the rare case all passengers originate from the same location and travel to the same destination, we will only call the successor function twice!
\end{itemize}

\subsubsection*{15. Space Complexity of Greedy Algorithm}
Assuming the scoring function requires $O(1)$ space, then the only thing stored is the path saved as $pickingOrder$. Thus, in the case where we expand the maximal number of junctions, the algorithm would require $O(k)$ space

\subsection*{Stochastic Algorithm}
\subsubsection*{16. Proof of Indifference to scaling}
Looking at the best $N$ points, their probabilities would be
$$
	p = \frac {\left(\frac {x_i}{\alpha}\right)^{-\frac{1}{T}}} {\sum_{N-best} {\left(\frac {x_i}{\alpha}\right)^{-\frac{1}{T}}}}
$$

since $\alpha$ is a constant (equal to $ \min x_i $, but still constant in the context of this equation):
$$
	p = \frac {\frac {1}{\alpha}\cdot x_i^{-\frac{1}{T}}} {\frac {1}{\alpha}\cdot \sum_{N-best} {x_i^{-\frac{1}{T}}}} = \frac {x_i^{-\frac{1}{T}}} {\sum_{N-best} {x_i^{-\frac{1}{T}}}}
$$

which is just the original, unnormalized probability!s

\subsubsection*{17. Temprature Experiment}
dsadsa

\subsubsection*{18. Implications of $T \rightarrow 0$}
In this case, the algorithm would be conservative and choose (almost determinstically - this would happen when $T=0$) the best score each time - as did the greedy algorithm!
This is implied by the normalized scoring function - the expression  $(\frac {x_i}{\alpha})^{-\frac{1}{T}}$ would become
$$
	\lim_{T \rightarrow 0} \left(\frac {x_i}{\alpha}\right)^{-\frac{1}{T}} = (\frac {x_i}{\alpha})^{-\infty}
$$

The original lowest value will have $\frac {x_i}{\alpha} = 1$, while all other values will have either $0$, or a quantity larger than $1$, thus the power would zero them out --- making the choice the lowest value!

\subsubsection*{19. Implications of $T \rightarrow \infty$}
In this case, the algorithm wouldn't be much of an algorithm, and choose arbitrarly.
This is implied by the scoring function - the expression  $(\frac {x_i}{\alpha})^{-\frac{1}{T}}$ would become
$$
	\lim_{T \rightarrow \infty} (x_i)^{-\frac{1}{T}} = x_i^0 = 1
$$

This would make the score of each of the best $N$ points to the equal to $\frac {1} {N}$, Thus making the algorithm choose completely randomly!

\subsubsection*{20. Stochastic Algorithm Experiment}
dsadsa

\subsubsection*{21. T-Test assumption verification}
dsadsa

\subsection*{A* (Again)}
\subsubsection*{22. Number of routes to \emph{any} Goal State}
Since there are $5$ orders in this problem set, we can use the table we calculated in Q1 in order to see that there are $113400$ different routes from the initial state to \textbf{a} goal state, since these routes are determined by all the possible permutations of junctions we visit.

\subsubsection*{23. Bus A* Experiment}
dsadsa

\subsubsection*{24. Comparison of Heuristics}
\subsubsection*{Non Admissable Heuristics}
\begin{itemize}
\item $h_c$ - because in the case where we have only one passenger left $(s_j, t_j)$, but we are at a junction very close to $t_j$, this heuristic would overshoot the optimal heuristic since it estimates the distance to a goal state by the aerial distance from that passengers source location to their destination. (and that passenger is already onboard the bus)

\item $h_g$ - although very similar to $h_b$, because the graph is directional - the actual distance from $s_1$ to $t_2$ (where $h_g = d_{A^*}(s_1, t_2)$) may be well over the distance needed to travel through \textbf{all} junctions in the orders. \\~\\
For example, if the route would be $ s_2 \rightarrow t_2 \rightarrow s_1 \rightarrow t_1 $, while a route exists between $ s_1 \rightarrow t_2 $, but \textbf{not} $ t_1 \rightarrow s_2 $, all with the following weights:
$$
	(s_2, t_2) = (t_2, s_1) = (s_1, t_1) = \delta
$$
$$
	(s_1, t_2) = 10\cdot \delta
$$

In such a case, our route (starting at $s_2$) would cost $3\cdot \delta$, while the heuristic would be $h_g = d(s_1, t_2) = 10\cdot \delta$ - meaning the heuristic is not admissable!

\end{itemize}

\subsubsection*{Admissable Heuristics}
\begin{itemize}
\item $h_a$ since it estimates the distance to a goal state by the largest aerial distance needed to transfer a passenger we haven't picked up yet from their location to their destination. If we were at their location, this would be a lower bound to the real distance to a goal state. Otherwise, we would also need to go and pick them up.

\item $h_b$ since it estimates the distance to a goal state by the largest aerial distance needed to transfer a passenger we haven't picked up yet to the destination of another passenger we haven't picked up yet. It is admissable because in the case we have two passengers, we would have three paths of action: \emph{Assuming 1 is closest to our location by real distance}
$$
	1. Pick up 1 \rightarrow Pick up 2 \rightarrow Drop off closest \rightarrow Drop off other
$$
$$
	2. Pick up 1 \rightarrow Pick up 2 \rightarrow Drop off farthest \rightarrow Drop off other
$$
$$
	3. Pick up 1 \rightarrow Drop off 1  \rightarrow Pick up 2 \rightarrow Drop off 2
$$
For case \#1 In the case where the drop off of \#2 is the closest, we would go through $s_1 \rightarrow s_2\rightarrow t_2 \rightarrow t_1$, which is bounded by $h_c = \max (s_1\rightarrow t_2, s_2 \rightarrow t_1)$ since we do a roundtrip through these points (vector calculus). In the case where it is closer to drop off \#1, we would go through $s_1 \rightarrow s_2 \rightarrow t_1 \rightarrow t_2$, which would imply the same. \\~\\
For case \#2 - everything is similar to the previous case, only the paths are vice versa. \\~\\
For case \#3, our route would include $t_1 \rightarrow s_2$, which is also $h_c$. \\~\\
\textbf{Note:} and if we have only one passenger, $h_b = h_a$

\item $h_d$ since it estimates the distance to a goal state by the largest aerial distance needed to get to a passenger we haven't picked up yet from our current location. Even if they are the last passenger left, we still have to go to their  location to pick them up, then travel to the destination. \\~\\
If our current location is between their source and destination, it is obvious that the optimal heuristic would be larger than this value. \ 
Otherwise, even if we have an aerial distance route from our current location, through they position, and then to the destination - it would still be the same as the real distance.

\item $h_e$ since it estimates the distance to a goal state by the largest aerial distance needed to get to a passenger we haven't picked up yet from our current location, and the largest aerial distance needed to transfer a passenger we haven't picked up yet to their destination. Even if these is a single passenger left, we still have to go to their  location to pick them up, then travel to the destination. \\~\\
If our current location is between their source and destination, it is obvious that the optimal heuristic would be larger than this value. \ 
Otherwise, even if we have an aerial distance route from our current location, through they position, and then to the destination - it would still be the same as the real distance. \\~\\
In the more general case, we have to get to our farthest away passenger awaiting pickup, and to drop off the passenger we haven't picked up yet who has to travel the longest, so this heuristic is indeed admissable!

\item $h_f$ - of course, since it is similar to $h_a$, only that it uses the real distance. (this is even though we are considering real distances in a directional graph - since we have to travel that distance from a passengers origin to their destionation in order to complete all orders)

\end{itemize}

\subsubsection*{Comparison of Admissable Heuristics}
Assuming \textbf{non-strict} admissability, we can conclude that
\begin{itemize}
	\item $h_b$ is more informed than $h_a$ since it acknowledges multiple passengers, and in the case where there is only a single passenger left it is equal to it.
	\item $h_e$ is more informed than $h_a, h_d$, since it is their addition (so $h_a, h_d < h_e \leq h^*$)
	\item $h_f$ is more informed than $h_a$, since it uses real distances instead of estimates
\end{itemize}

\textbf{Note:} If we were to address \textbf{strict} admissability, since the case that there is only one passenger left to pickup $h_a = h_b$, and in the case that the real distances are aerial distances $h_a = h_f$ (and transetively in both cases $h_a = h_f$), the only better informed heursitic would be $h_e$ over all the others (since we have to pick the passenger up ($(s_i,  t_i) \in s.W$) and the invarient that $s_i \neq t_i$

\subsubsection*{25. Using an admissable Heuristic}
dsadsa

\subsubsection*{26. Using an advanced Heuristic}
dsadsa

\section*{Theory}
\subsection*{Proof of transitive admissability}
The condition for a heursitic to be admissable is that 
$$ 0 \leq h \leq h^* $$
Assuming that is true for $h$ (for the states where it is defined), we can check if $h_0$ is admissable by its definition: \\ 
For any state $s$:
\begin{itemize}
\item if $h$ is defined for $s$, then $h_0(h,s) = h(s)$, yielding $h_0(h,s) \leq h^*(s) $
\item if $h$ is not defined for $s$, then $h_0(h,s) = 0$, thus still holding that $  h_0(h,s) = 0 \leq h^*(s) $
\end{itemize}

\textbf{Note: } of course, $0 \leq h_0$, since $h$ is admissable. \\ \\

Thus, we can conclude that $ h\ is\ addmissable \rightarrow h_0\ is\ addmissable $

\subsection*{A better heuristic under the assumption of a Tree-Graph}
We will use Uniform-cost in cases where the partial heuristic function $h$ is not defined, to try and find a goal state
\[
  h_{tree}(h,s)=\begin{cases}
               h(s) \ \ \ \ \  Applicable_h(s) \\
               \Delta \ \ \ \ \ \ \ \  \  Uniform-Cost\ found\ goal\ state\ at\ (relative)\ cost\ \Delta
            \end{cases}
\]

This heuristic is admissable since
\begin{itemize}
\item the first case is exactly as it were previously
\item Uniform cost is optimal, hence $\Delta = h^* $
\end{itemize}
\ 

It is obvious that $h_{tree}$ is more informed, since it is equal to $h$ in the first case, and higher is the second.
\\~\\
\textbf{Note: } We are using the weaker constraint, only since the question isn't possible to answer using the usual constraint --- since $h$ may be optimal when defined.
\\~\\

\begin{algorithm}
\caption{Pseudo Code for Heuristic}
\begin{algorithmic}[1]
\Procedure{heuristic}{$h, state$}
\If {h.isApplicableTo(state)} \Comment{just use partial heuristic}
	\State \textbf{return} $h(s)$
\EndIf
\State
\State \textbf{return} \emph{Uniform-Cost}$(s, goal\_predicate)$
\Comment{use UC}
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection*{A generic better heuristic!}
Actually, the previous heuristic still works, since we know the cost function has a positive minimal constraint.
\\~\\
\textbf{Note: } Since we used the same heuristic in both answers, to be fair --- we could have used another heuristic that returns $\delta$ (the minimum constraint) when $h$ is not defined and $s$ is not a goal state (in both cases, as well)

\subsection*{Using a perfect (but limited) heuristic to create an admissable heuristic}
As we learned in the lecture, using a perfect heuristic --- $A*$ is an optimal algorithm, and no algorithm exists that can perform better.\ 
When using a heuristic such as $h_0$, where all non-start states have the same value, $A*$ behaves like Uniform-Cost. (Especially since $h=0$ meaning $f=g+h=g$)
\\~\\
Thus, Since $A*$ doesn't know that the heuristic is partial (but optimal for the initial state) --- we can use that for our advantage, by using Uniform-Cost with an upper bound - $h(s_i)$. This algorithm will not open states where $h(s_i) <= g(s)$.
\\~\\
This algorithm is an improvement over $A*$ because Unlike usual Uniform-Cost search, it knows the goal value, so once it reaches a state with that cost it can stop (less runtime). On the other hand, $A*$/Uniform-Cost would need to open all states with that cost before it can halt.


\end{document}